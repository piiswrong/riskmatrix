{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import bottleneck\n",
    "import matplotlib.pyplot as plt\n",
    "from riskmatrix.alpha.alpha101_new import compute_alpha101\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER_SYMBOLS = ['BTCUSDT', 'ETHUSDT', 'SOLUSDT', 'XRPUSDT', 'DOGEUSDT', 'BNBUSDT', 'ADAUSDT', '1000SHIBUSDT', 'MATICUSDT', 'AVAXUSDT', 'ETCUSDT', 'LTCUSDT', 'LINKUSDT', 'DOTUSDT', 'FTMUSDT', '1000PEPEUSDT', 'GMTUSDT', 'BCHUSDT', 'FILUSDT', 'SANDUSDT', 'NEARUSDT', 'EOSUSDT', 'AXSUSDT', 'GALAUSDT', 'APEUSDT', 'ATOMUSDT', 'MANAUSDT', 'APTUSDT', 'OPUSDT', 'TRXUSDT', 'DYDXUSDT', 'ORDIUSDT', 'CHZUSDT', 'TRBUSDT', 'WIFUSDT', 'CRVUSDT', 'ARBUSDT', 'UNIUSDT', 'SUIUSDT', 'WLDUSDT', 'AAVEUSDT', 'WAVESUSDT', 'PEOPLEUSDT', 'SUSHIUSDT', 'MASKUSDT', 'RUNEUSDT', 'XLMUSDT', 'THETAUSDT', 'INJUSDT', 'LRCUSDT', 'CFXUSDT', 'VETUSDT', 'ALGOUSDT', 'ALICEUSDT', 'ZILUSDT', 'SXPUSDT', 'XTZUSDT', 'GRTUSDT', 'LINAUSDT', 'MKRUSDT', 'TIAUSDT', 'STORJUSDT', 'UNFIUSDT', '1000BONKUSDT', 'NOTUSDT', 'ENJUSDT', 'NEOUSDT', 'EGLDUSDT', 'FETUSDT', '1INCHUSDT', '1000LUNCUSDT', 'STXUSDT', 'COMPUSDT', 'YFIUSDT', 'ONEUSDT', 'KNCUSDT', 'LDOUSDT', '1000SATSUSDT', 'SNXUSDT', 'ZECUSDT', 'ENSUSDT', 'OMGUSDT', 'BOMEUSDT', 'SEIUSDT', 'MTLUSDT', 'BLZUSDT', 'REEFUSDT', 'CHRUSDT', 'BAKEUSDT', 'KAVAUSDT', '1000FLOKIUSDT', 'ENAUSDT', 'RSRUSDT', 'XMRUSDT', 'RNDRUSDT', 'RLCUSDT', 'OGNUSDT', 'JASMYUSDT', 'BELUSDT', 'OCEANUSDT']\n",
    "# FILTER_SYMBOLS = ['BCHUSDT',  'BTCUSDT',  'ETHUSDT',  'XRPUSDT',  'EOSUSDT',  'LTCUSDT',  'TRXUSDT',  'ETCUSDT',  'LINKUSDT',  'XLMUSDT',  'ADAUSDT',  'XMRUSDT',  'DASHUSDT',  'ZECUSDT',  'XTZUSDT',  'ATOMUSDT',  'BNBUSDT',  'ONTUSDT',  'IOTAUSDT',  'BATUSDT',  'VETUSDT',  'NEOUSDT',  'QTUMUSDT',  'IOSTUSDT',  'THETAUSDT',  'ALGOUSDT',  'ZILUSDT',  'KNCUSDT',  'ZRXUSDT',  'COMPUSDT',  'OMGUSDT',  'DOGEUSDT',  'SXPUSDT',  'LENDUSDT',  'KAVAUSDT',  'BANDUSDT',  'RLCUSDT',  'WAVESUSDT',  'MKRUSDT',  'SNXUSDT',  'DOTUSDT',  'DEFIUSDT',  'YFIUSDT',  'BALUSDT',  'CRVUSDT',  'TRBUSDT',  'YFIIUSDT',  'RUNEUSDT',  'SUSHIUSDT',  'BZRXUSDT',  'SRMUSDT',  'EGLDUSDT',  'SOLUSDT',  'ICXUSDT',  'STORJUSDT',  'BLZUSDT',  'UNIUSDT',  'AVAXUSDT',  'FTMUSDT',  'HNTUSDT',  'ENJUSDT',  'FLMUSDT',  'TOMOUSDT',  'RENUSDT',  'KSMUSDT',  'NEARUSDT',  'AAVEUSDT',  'FILUSDT',  'LRCUSDT',  'RSRUSDT',  'MATICUSDT',  'OCEANUSDT',  'CVCUSDT',  'BELUSDT',  'CTKUSDT',  'AXSUSDT',  'ALPHAUSDT',  'ZENUSDT',  'SKLUSDT',  'GRTUSDT',  '1INCHUSDT',  'AKROUSDT',  'DOTECOUSDT',  'CHZUSDT',  'SANDUSDT',  'ANKRUSDT',  'LUNAUSDT',  'BTSUSDT',  'LITUSDT',  'DODOUSDT',  'UNFIUSDT',  'REEFUSDT',  'RVNUSDT',  'SFPUSDT',  'XEMUSDT',  'BTCSTUSDT',  'COTIUSDT',  'CHRUSDT',  'MANAUSDT',  'ALICEUSDT',  'HBARUSDT',  'ONEUSDT',  'LINAUSDT',  'STMXUSDT',  'DENTUSDT',  'CELRUSDT',  'HOTUSDT',  'MTLUSDT',  'OGNUSDT',  'BTTUSDT',  'NKNUSDT',  'SCUSDT',  'DGBUSDT',  '1000SHIBUSDT',  'BAKEUSDT',  'GTCUSDT',  'KEEPUSDT',  'IOTXUSDT',  'AUDIOUSDT',  'RAYUSDT',  'C98USDT',  'MASKUSDT',  'ATAUSDT',  'DYDXUSDT',  '1000XECUSDT',  'GALAUSDT',  'CELOUSDT',  'ARUSDT',  'KLAYUSDT',  'ARPAUSDT',  'NUUSDT',  'CTSIUSDT',  'LPTUSDT',  'ENSUSDT',  'PEOPLEUSDT',  'ANTUSDT',  'ROSEUSDT',  'DUSKUSDT',  '1000BTTCUSDT',  'FLOWUSDT',  'IMXUSDT',  'API3USDT',  'ANCUSDT',  'GMTUSDT',  'APEUSDT',  'WOOUSDT',  'FTTUSDT',  'JASMYUSDT',  'DARUSDT',  'GALUSDT',  'OPUSDT',  'INJUSDT',  'STGUSDT',  'FOOTBALLUSDT',  'SPELLUSDT',  '1000LUNCUSDT',  'LUNA2USDT',  'CVXUSDT',  'LDOUSDT',  'ICPUSDT',  'APTUSDT',  'QNTUSDT',  'BLUEBIRDUSDT',  'FETUSDT',  'FXSUSDT',  'HOOKUSDT',  'MAGICUSDT',  'TUSDT',  'RNDRUSDT',  'HIGHUSDT',  'MINAUSDT',  'ASTRUSDT',  'AGIXUSDT',  'PHBUSDT',  'GMXUSDT',  'CFXUSDT',  'COCOSUSDT',  'STXUSDT',  'ACHUSDT',  'BNXUSDT',  'SSVUSDT',  'CKBUSDT',  'PERPUSDT',  'TRUUSDT',  'LQTYUSDT',  'ARBUSDT',  'IDUSDT',  'JOEUSDT',  'AMBUSDT',  'LEVERUSDT',  'TLMUSDT',  'RDNTUSDT',  'HFTUSDT',  'XVSUSDT',  'BLURUSDT',  'EDUUSDT',  'IDEXUSDT',  'SUIUSDT',  '1000PEPEUSDT',  '1000FLOKIUSDT',  'RADUSDT',  'UMAUSDT',  'KEYUSDT',  'COMBOUSDT',  'NMRUSDT',  'MAVUSDT',  'MDTUSDT',  'XVGUSDT',  'WLDUSDT',  'ARKMUSDT',  'PENDLEUSDT',  'AGLDUSDT',  'YGGUSDT',  'DODOXUSDT',  'BNTUSDT',  'OXTUSDT',  'SEIUSDT',  'CYBERUSDT',  'HIFIUSDT',  'ARKUSDT',  'FRONTUSDT',  'GLMRUSDT',  'BICOUSDT',  'LOOMUSDT',  'STRAXUSDT',  'BIGTIMEUSDT',  'BONDUSDT',  'ORBSUSDT',  'STPTUSDT',  'WAXPUSDT',  'BSVUSDT',  'RIFUSDT',  'GASUSDT',  'POLYXUSDT',  'POWRUSDT',  'SLPUSDT',  'TIAUSDT',  'CAKEUSDT',  'SNTUSDT',  'MEMEUSDT',  'TOKENUSDT',  'TWTUSDT',  'ORDIUSDT',  'STEEMUSDT',  'BADGERUSDT',  'ILVUSDT',  'MBLUSDT',  'NTRNUSDT',  'BEAMXUSDT',  'KASUSDT',  '1000BONKUSDT',  'PYTHUSDT',  'SUPERUSDT',  'ONGUSDT',  'USTCUSDT',  'ETHWUSDT',  'JTOUSDT',  '1000SATSUSDT',  '1000RATSUSDT',  'AUCTIONUSDT',  'ACEUSDT',  'MOVRUSDT',  'NFPUSDT',  'AIUSDT',  'XAIUSDT',  'MANTAUSDT',  'WIFUSDT',  'ONDOUSDT',  'ALTUSDT',  'LSKUSDT',  'JUPUSDT',  'ZETAUSDT',  'RONINUSDT',  'DYMUSDT',  'OMUSDT',  'PIXELUSDT',  'STRKUSDT',  'MAVIAUSDT',  'GLMUSDT',  'PORTALUSDT',  'AXLUSDT',  'TONUSDT',  'MYROUSDT',  'METISUSDT',  'AEVOUSDT',  'VANRYUSDT',  'BOMEUSDT',  'ETHFIUSDT',  'ENAUSDT',  'WUSDT',  'TNSRUSDT',  'SAGAUSDT',  'TAOUSDT',  'OMNIUSDT',  'REZUSDT',  'BBUSDT',  'NOTUSDT',  'TURBOUSDT',  'IOUSDT',  'MEWUSDT',  'ZKUSDT',  'LISTAUSDT',  'ZROUSDT',  'RENDERUSDT']\n",
    "FILTER_SYMBOLS = ['1INCHUSDT',  'AAVEUSDT',  'ADAUSDT',  'ALGOUSDT',  'ALPHAUSDT',  'ATOMUSDT',  'AVAXUSDT',  'AXSUSDT',  'BALUSDT',  'BANDUSDT',  'BATUSDT',  'BCHUSDT',  'BELUSDT',  'BLZUSDT',  'BNBUSDT',  'BTCUSDT',  'BZRXUSDT',  'COMPUSDT',  'CRVUSDT',  'CTKUSDT',  'CVCUSDT',  'DASHUSDT',  'DEFIUSDT',  'DOGEUSDT',  'DOTUSDT',  'EGLDUSDT',  'ENJUSDT',  'EOSUSDT',  'ETCUSDT',  'ETHUSDT',  'FILUSDT',  'FLMUSDT',  'FTMUSDT',  'GRTUSDT',  'HNTUSDT',  'ICXUSDT',  'IOSTUSDT',  'IOTAUSDT',  'KAVAUSDT',  'KNCUSDT',  'KSMUSDT',  'LINKUSDT',  'LRCUSDT',  'LTCUSDT',  'MATICUSDT',  'MKRUSDT',  'NEARUSDT',  'NEOUSDT',  'OCEANUSDT',  'OMGUSDT',  'ONTUSDT',  'QTUMUSDT',  'RENUSDT',  'RLCUSDT',  'RSRUSDT',  'RUNEUSDT',  'SKLUSDT',  'SNXUSDT',  'SOLUSDT',  'SRMUSDT',  'STORJUSDT',  'SUSHIUSDT',  'SXPUSDT',  'THETAUSDT',  'TOMOUSDT',  'TRBUSDT',  'TRXUSDT',  'UNIUSDT',  'VETUSDT',  'WAVESUSDT',  'XLMUSDT',  'XMRUSDT',  'XRPUSDT',  'XTZUSDT',  'YFIIUSDT',  'YFIUSDT',  'ZECUSDT',  'ZENUSDT',  'ZILUSDT',  'ZRXUSDT',  'AKROUSDT',  'DOTECOUSDT',  'CHZUSDT',  'SANDUSDT',  'ANKRUSDT',  'LUNAUSDT',  'BTSUSDT',  'LITUSDT',  'DODOUSDT',  'UNFIUSDT',  'REEFUSDT',  'RVNUSDT',  'SFPUSDT',  'XEMUSDT',  'BTCSTUSDT',  'COTIUSDT',  'CHRUSDT',  'MANAUSDT',  'ALICEUSDT',  'HBARUSDT',  'ONEUSDT',  'LINAUSDT',  'STMXUSDT',  'DENTUSDT',  'CELRUSDT',  'HOTUSDT',  'MTLUSDT',  'OGNUSDT',  'BTTUSDT',  'NKNUSDT',  'SCUSDT',  'DGBUSDT',  '1000SHIBUSDT',  'BAKEUSDT',  'GTCUSDT',  'KEEPUSDT',  'IOTXUSDT',  'AUDIOUSDT',  'RAYUSDT',  'C98USDT',  'MASKUSDT',  'ATAUSDT',  'DYDXUSDT',  '1000XECUSDT',  'GALAUSDT',  'CELOUSDT',  'ARUSDT',  'KLAYUSDT',  'ARPAUSDT',  'NUUSDT',  'CTSIUSDT',  'LPTUSDT',  'ENSUSDT',  'PEOPLEUSDT',  'ANTUSDT',  'ROSEUSDT',  'DUSKUSDT',  '1000BTTCUSDT',  'FLOWUSDT',  'IMXUSDT',  'API3USDT',  'ANCUSDT',  'GMTUSDT',  'APEUSDT',  'WOOUSDT',  'FTTUSDT',  'JASMYUSDT',  'DARUSDT',  'GALUSDT',  'OPUSDT',  'INJUSDT',  'STGUSDT',  'FOOTBALLUSDT',  'SPELLUSDT',  '1000LUNCUSDT',  'LUNA2USDT',  'CVXUSDT',  'LDOUSDT',  'ICPUSDT',  'APTUSDT',  'QNTUSDT',  'BLUEBIRDUSDT',  'FETUSDT',  'FXSUSDT',  'HOOKUSDT',  'MAGICUSDT',  'TUSDT',  'RNDRUSDT',  'HIGHUSDT',  'MINAUSDT',  'ASTRUSDT',  'AGIXUSDT',  'PHBUSDT',  'GMXUSDT',  'CFXUSDT',  'COCOSUSDT',  'STXUSDT',  'ACHUSDT',  'BNXUSDT',  'SSVUSDT',  'CKBUSDT',  'PERPUSDT',  'TRUUSDT',  'LQTYUSDT',  'ARBUSDT',  'IDUSDT',  'JOEUSDT',  'AMBUSDT',  'LEVERUSDT',  'TLMUSDT',  'RDNTUSDT',  'HFTUSDT',  'XVSUSDT',  'BLURUSDT',  'EDUUSDT',  'IDEXUSDT',  'SUIUSDT',  '1000PEPEUSDT',  '1000FLOKIUSDT',  'RADUSDT',  'UMAUSDT',  'KEYUSDT',  'COMBOUSDT',  'NMRUSDT',  'MAVUSDT',  'MDTUSDT',  'XVGUSDT',  'WLDUSDT',  'ARKMUSDT',  'PENDLEUSDT',  'AGLDUSDT',  'YGGUSDT',  'DODOXUSDT',  'BNTUSDT',  'OXTUSDT',  'SEIUSDT',  'CYBERUSDT',  'HIFIUSDT',  'ARKUSDT',  'FRONTUSDT',  'GLMRUSDT',  'BICOUSDT',  'LOOMUSDT',  'STRAXUSDT',  'BIGTIMEUSDT',  'BONDUSDT',  'ORBSUSDT',  'STPTUSDT',  'WAXPUSDT',  'BSVUSDT',  'RIFUSDT',  'GASUSDT',  'POLYXUSDT',  'POWRUSDT',  'SLPUSDT',  'TIAUSDT',  'CAKEUSDT',  'SNTUSDT',  'MEMEUSDT',  'TOKENUSDT',  'TWTUSDT',  'ORDIUSDT',  'STEEMUSDT',  'BADGERUSDT',  'ILVUSDT',  'MBLUSDT',  'NTRNUSDT',  'BEAMXUSDT',  'KASUSDT',  '1000BONKUSDT',  'PYTHUSDT',  'SUPERUSDT',  'ONGUSDT',  'USTCUSDT',  'ETHWUSDT',  'JTOUSDT',  '1000SATSUSDT',  '1000RATSUSDT',  'AUCTIONUSDT',  'ACEUSDT',  'MOVRUSDT',  'NFPUSDT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_past_close_return(df: pl.DataFrame, N: int):\n",
    "    for i in range(N):\n",
    "        df = df.with_columns(\n",
    "            ((pl.col(\"close\") / pl.col(\"close\").shift(i+1) - 1) * 100)\n",
    "            .over(\"symbol\")  # Applying the function over each symbol group\n",
    "            .alias(f'past_close_return_{i+1}')\n",
    "        )\n",
    "    df = df.with_columns(returns=pl.col('past_close_return_1'))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_future_close_return(df: pl.DataFrame, N: int):\n",
    "    for i in range(N):\n",
    "        df = df.with_columns(\n",
    "            ((pl.col(\"close\").shift(-(i+1)) / pl.col(\"close\") - 1) * 100)\n",
    "            .over(\"symbol\")  # Applying the function over each symbol group\n",
    "            .alias(f'future_close_return_{i+1}')\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_binance_data(filename, filter_symbols=None):\n",
    "    # read parquet file with pandas\n",
    "    df = pl.read_parquet(filename)\n",
    "    # df = df.with_columns(vwap=pl.col('quote_volume')/pl.col('volume'))\n",
    "    df = df.with_columns(open_time=pl.from_epoch(pl.col(\"open_time\"), time_unit=\"ms\").cast(pl.Datetime('ms')))\n",
    "    df = df.with_columns(close_time=pl.from_epoch(pl.col(\"close_time\"), time_unit=\"ms\").cast(pl.Datetime('ms')))\n",
    "\n",
    "    # filter symbols ending in USDT\n",
    "    if filter_symbols is not None:\n",
    "        df = df.filter(pl.col(\"symbol\").is_in(filter_symbols))\n",
    "    # FILTER_SYMBOLS = df[['symbol', 'quote_volume']].groupby('symbol').sum().sort_values('quote_volume', ascending=False).index.to_list()[:100]\n",
    "    df = df.sort(by=['symbol', 'open_time'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(df):\n",
    "    df = compute_past_close_return(df, 10)\n",
    "    df = compute_future_close_return(df, 10)\n",
    "    df = compute_alpha101(df)\n",
    "\n",
    "    df = df.with_columns(\n",
    "        (\n",
    "            pl.col('returns').abs().rolling_sum(window_size=10)/\n",
    "            pl.col('quote_volume').rolling_sum(window_size=10) + 1\n",
    "        ).log().over('symbol').alias('alpha_amihud')\n",
    "    )\n",
    "\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"return\").rolling_skew(20).over(\"symbol\").alias(\"alpha_return_skew\")\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def alpha_sanity_check(df, cutoff):\n",
    "    df1 = df\n",
    "    df2 = df.clone()\n",
    "    feature1 = compute_features(df1)\n",
    "    df2 = df2.with_columns(\n",
    "        *[\n",
    "            pl.when(pl.col('open_time') >= cutoff).then(pl.lit(None)).otherwise(pl.col(col)).alias(col)\n",
    "            for col in df2.columns if col != 'open_time' and col != 'symbol' and col != 'close_time'\n",
    "        ]\n",
    "    )\n",
    "    feature2 = compute_features(df2)\n",
    "\n",
    "    assert df1.frame_equal(feature1[df1.columns])\n",
    "    assert df2.frame_equal(feature2[df2.columns])\n",
    "\n",
    "    feature1 = feature1.filter(pl.col('open_time') < cutoff)\n",
    "    feature2 = feature2.filter(pl.col('open_time') < cutoff)\n",
    "\n",
    "    for col in feature1.columns:\n",
    "        if not feature1[col].equals(feature2[col]):\n",
    "            print(col, (feature1[col] - feature2[col]).abs().max())\n",
    "\n",
    "    assert feature1.frame_equal(feature2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(df, alphaname, long_quantile=None, short_quantile=None, commission=0.1):\n",
    "    assert long_quantile is not None or short_quantile is not None\n",
    "    returns = df[[\"open_time\", \"symbol\", \"returns\"]].pivot(index=\"open_time\", columns=\"symbol\", values=\"returns\").sort(\"open_time\")\n",
    "    alpha = df[[\"open_time\", \"symbol\", alphaname]].pivot(index=\"open_time\", columns=\"symbol\", values=alphaname).sort(\"open_time\")\n",
    "\n",
    "    assert (returns[\"open_time\"] == alpha[\"open_time\"]).all()\n",
    "    time_steps = returns[\"open_time\"].to_numpy()\n",
    "    columns = returns.columns[1:]\n",
    "    returns = np.nan_to_num(returns[columns].to_numpy(), 0.0)\n",
    "    alpha = alpha[columns].to_numpy().astype(np.float64)\n",
    "\n",
    "    quantiles = np.nanquantile(alpha, [short_quantile if short_quantile is not None else 0, long_quantile if long_quantile is not None else 0], axis=1)\n",
    "    \n",
    "    holdings = np.zeros_like(alpha)\n",
    "    weight = 0.5 if long_quantile is not None and short_quantile is not None else 1.0\n",
    "    if short_quantile is not None:\n",
    "        short_threshold = np.expand_dims(quantiles[0], axis=-1)\n",
    "        short_holdings = alpha < short_threshold\n",
    "        short_holdings = - weight / short_holdings.sum(axis=1, keepdims=True) * short_holdings\n",
    "        # use previous step's alpha to decide next step's holding\n",
    "        holdings[1:] += short_holdings[:-1]\n",
    "    if long_quantile is not None:\n",
    "        long_threshold = np.expand_dims(quantiles[1], axis=-1)\n",
    "        long_holdings = alpha > long_threshold\n",
    "        long_holdings = weight / long_holdings.sum(axis=1, keepdims=True) * long_holdings\n",
    "        holdings[1:] += long_holdings[:-1]\n",
    "\n",
    "    nans = np.isnan(holdings)\n",
    "    has_nan = np.any(nans, axis=1)\n",
    "    all_nan = np.all(nans, axis=1)\n",
    "    # check that holdings should either be all valid or all nan at each time step\n",
    "    assert (has_nan == all_nan).all()\n",
    "    holdings = bottleneck.push(holdings, axis=0)\n",
    "\n",
    "    pnl = (holdings * returns).sum(axis=1)\n",
    "\n",
    "    if commission > 0:\n",
    "        holdings_at_close = holdings * (1 + returns/100)\n",
    "        holdings_at_close /= np.abs(holdings_at_close).sum(axis=-1, keepdims=True) + 1e-8\n",
    "        pnl[1:] -= commission * np.abs(holdings[1:] - holdings_at_close[:-1]).sum(axis=1)\n",
    "\n",
    "    return time_steps, pnl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_alphas(df, factors, long_quantile=None, short_quantile=None, commission=0.0, try_invert=True):\n",
    "    res = {}\n",
    "    for alphaname in factors:\n",
    "        if alphaname not in df.columns:\n",
    "            continue\n",
    "        time_steps, pnl = backtest(df, alphaname, long_quantile=long_quantile, short_quantile=short_quantile, commission=commission)\n",
    "        net = (1+pnl/100).cumprod()\n",
    "        if try_invert and net[-1] < 1:\n",
    "            df = df.with_columns(**{alphaname: -df[alphaname]})\n",
    "            time_steps_invert, pnl_invert = backtest(df, alphaname, long_quantile=long_quantile, short_quantile=short_quantile, commission=commission)\n",
    "            net_invert = (1+pnl_invert/100).cumprod()\n",
    "            if net_invert[-1] > net[-1]:\n",
    "                time_steps, pnl, net = time_steps_invert, pnl_invert, net_invert\n",
    "\n",
    "        res[alphaname] = {\n",
    "            \"alphaname\": alphaname,\n",
    "            \"sharpe\": np.sqrt(365) * np.mean(pnl) / np.std(pnl),\n",
    "            \"ann_ret\": 365 * np.mean(pnl),\n",
    "        }\n",
    "        print(res[alphaname])\n",
    "        plt.plot(time_steps, net, label=alphaname)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return res\n",
    "    # plt.scatter(ann_ret, max_dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_correlations(df, factors):\n",
    "    res = []\n",
    "    for alphaname in factors:\n",
    "        if alphaname not in df.columns:\n",
    "            continue\n",
    "        res.append(df.select(alphaname=pl.lit(alphaname), *[pl.corr(alphaname, f\"future_close_return_{i}\").alias(f'corr{i}') for i in range(1, 11)]))\n",
    "        plt.plot(np.abs(res[-1].drop('alphaname').to_numpy().squeeze()))\n",
    "    plt.show()\n",
    "    res = pl.concat(res)\n",
    "    res = res.sort('corr10', descending=True)\n",
    "    return res\n",
    "# alpha_correlations(df, [i for i in df.columns if i.startswith('alpha')])\n",
    "# df.select(pl.rolling_corr('alpha_amihud', 'future_close_return_1', window_size=100).over('symbol').sum().over('open_time').alias('r1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = read_binance_data(\"../data/all_data_1d.parquet\", filter_symbols=FILTER_SYMBOLS)\n",
    "# # df = df.filter(pl.col('open_time') < pl.date(2022, 1, 1))\n",
    "# # alpha_sanity_check(df, pl.date(2021, 6, 1))\n",
    "# df = compute_features(df)\n",
    "# df.write_parquet(\"../data/1d_262_alpha101_new.parquet\")\n",
    "df = pl.read_parquet(\"../data/1d_262_alpha101_new.parquet\")\n",
    "# df2 = pl.read_parquet(\"../data/1d_262_alpha_new.parquet\")\n",
    "#df = df[[i for i in df2.columns if i in df.columns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_future_close_return_ranks(df, N):\n",
    "    for i in range(1, N+1):\n",
    "        col = f\"future_close_return_{i}\"\n",
    "        rankdf = df[['open_time', 'symbol', col]].filter(pl.col(col).is_not_null())\n",
    "        rankdf = rankdf.with_columns(\n",
    "            (pl.col(col).rank()/pl.col(col).count()).over(\"open_time\").alias(f'{col}_rank')\n",
    "        ).drop(col)\n",
    "        df = df.join(rankdf, on=['open_time', 'symbol'], how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(df, long_quantile=None, short_quantile=None, commission=0.0):\n",
    "    with_commission = backtest_alphas(df, [i for i in df.columns if i.startswith('alpha')], long_quantile=long_quantile, short_quantile=short_quantile, commission=commission)\n",
    "    without_commission = backtest_alphas(df, [i for i in df.columns if i.startswith('alpha')], long_quantile=long_quantile, short_quantile=short_quantile, commission=0.0)\n",
    "    for name, info in with_commission.items():\n",
    "        info['sharpe_without_commission'] = without_commission[name]['sharpe']\n",
    "    return with_commission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trial(df, x_cols, y_col_name, pred_col_name, param, n_round, begin, train_end, predict_end):\n",
    "    # df = pl.read_parquet(\"../data/1d_262_alpha_new.parquet\")\n",
    "    # df=df\n",
    "    # x_cols=['^alpha.*$']\n",
    "    # y_col='returns'\n",
    "    # param={'objective': 'reg:squarederror'}\n",
    "    # n_round=1000\n",
    "    # begin=pl.date(2021, 1, 1)\n",
    "    # train_delta=pl.duration(days=365)\n",
    "    # predict_delta=pl.duration(days=30)\n",
    "\n",
    "    ind_col = pl.col(\"open_time\")\n",
    "    x_cols = [pl.col(i) for i in x_cols]\n",
    "    y_col = pl.col(y_col_name)\n",
    "\n",
    "    data = df.select(ind_col, pl.col(\"symbol\"), *x_cols, y_col)\n",
    "\n",
    "    train_data = data.filter((ind_col >= begin) & (ind_col < train_end))\n",
    "    train_data = train_data.filter(y_col.is_not_null())\n",
    "    test_data = data.filter((ind_col >= train_end) & (ind_col < predict_end))\n",
    "\n",
    "    train_x = train_data.select(*x_cols)\n",
    "    columns = sorted(train_x.columns)\n",
    "    # sort columns by name\n",
    "    train_x = train_x[columns].to_numpy()\n",
    "    train_y = train_data.select(y_col).to_numpy()\n",
    "\n",
    "    x_limits = np.nanquantile(train_x, [0.01, 0.99], axis=0)\n",
    "    train_x = np.clip(train_x, x_limits[0], x_limits[1])\n",
    "    y_limits = np.nanquantile(train_y, [0.01, 0.99])\n",
    "    train_y = np.clip(train_y, y_limits[0], y_limits[1])\n",
    "\n",
    "    mean_x = np.nanmean(train_x, axis=0)\n",
    "    std_x = np.nanstd(train_x, axis=0) + 1e-10\n",
    "    train_x = (train_x - mean_x) / std_x\n",
    "\n",
    "    mean_y = np.nanmean(train_y, axis=0)\n",
    "    std_y = np.nanstd(train_y, axis=0) + 1e-10\n",
    "    train_y = (train_y - mean_y) / std_y\n",
    "\n",
    "    test_x = test_data[columns].to_numpy()\n",
    "    test_y = test_data.select(y_col).to_numpy()\n",
    "    test_x = np.clip(test_x, x_limits[0], x_limits[1])\n",
    "    test_y = np.clip(test_y, y_limits[0], y_limits[1])\n",
    "\n",
    "    test_x = (test_x - mean_x) / std_x\n",
    "    test_y = (test_y - mean_y) / std_y\n",
    "\n",
    "    # train using linear regression\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    model = LinearRegression()\n",
    "    model.fit(np.nan_to_num(train_x, 0), np.nan_to_num(train_y, 0))\n",
    "    prediction = model.predict(np.nan_to_num(test_x)).squeeze()\n",
    "\n",
    "    # train_mat = xgb.DMatrix(train_x, label=train_y)\n",
    "    # bst = xgb.train(param, train_mat, num_boost_round=n_round)\n",
    "    # test_mat = xgb.DMatrix(test_x, label=None)\n",
    "    # prediction = bst.predict(test_mat)\n",
    "\n",
    "    return pl.DataFrame({\"open_time\": test_data[\"open_time\"], \"symbol\": test_data[\"symbol\"], pred_col_name: prediction})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roll(df, x_cols, y_col, pred_col, start, predict_steps, max_train_steps, param, n_round):\n",
    "    time_steps = df[\"open_time\"].unique()\n",
    "\n",
    "    preds = []\n",
    "    for begin in range(start, len(time_steps) - 1, predict_steps):\n",
    "        preds.append(\n",
    "            trial(df, x_cols, y_col, pred_col, param, n_round,\n",
    "                  time_steps[max(0, begin - max_train_steps)],\n",
    "                  time_steps[begin],\n",
    "                  time_steps[min(len(time_steps)-1, begin+predict_steps)]))\n",
    "\n",
    "    return df.join(pl.concat(preds), on=[\"open_time\", \"symbol\"], how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_infos = feature_selection(df, long_quantile=0.7, short_quantile=0.3, commission=0.03)\n",
    "nan_alphas = [i for i, info in alpha_infos.items() if np.isnan(info['sharpe'])]\n",
    "sorted_alphas = sorted([i for i in alpha_infos.values() if not np.isnan(i['sharpe_without_commission'] - i['sharpe'])], key=lambda x: x['sharpe_without_commission'] - x['sharpe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pl.read_parquet(\"../data/1d_262_alpha_new.parquet\")\n",
    "\n",
    "for y_col_name in [f\"future_close_return_{i}\" for i in range(1, 11)]:\n",
    "\n",
    "    start = 100\n",
    "    max_train_steps = 500\n",
    "    predict_steps = 100\n",
    "    param={\n",
    "        'objective': 'reg:squarederror',\n",
    "        'max_depth': 6\n",
    "    }\n",
    "    n_round=100\n",
    "\n",
    "    x_cols=[i['alphaname'] for i in sorted_alphas[30:]] + nan_alphas\n",
    "    y_col=y_col_name\n",
    "    dfalpha = roll(df, x_cols, y_col, \"bad_prediction\", start, predict_steps, max_train_steps, param, n_round)\n",
    "    dfalpha = dfalpha.with_columns(target=pl.col(y_col_name) - pl.col(\"bad_prediction\"))\n",
    "\n",
    "    x_cols=[i['alphaname'] for i in sorted_alphas if i['sharpe'] > 1.0]\n",
    "    y_col='target'\n",
    "    dfalpha = roll(dfalpha, x_cols, y_col, \"prediction\", start+start, predict_steps, max_train_steps, param, n_round)\n",
    "\n",
    "    dfalpha = dfalpha.filter(pl.col(\"open_time\") >= dfalpha[\"open_time\"].unique()[start+start])\n",
    "    backtest_alphas(dfalpha, [\"prediction\"], long_quantile=0.7, short_quantile=0.3, commission=0.1, try_invert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(\n",
    "        (\n",
    "            \n",
    "            pl.col('quote_volume').rolling_sum(window_size=5) + 1\n",
    "        ).over('symbol').alias('alpha_test')\n",
    "    )\n",
    "backtest_alphas(df, ['alpha_test', 'alpha_amihud'], long_quantile=0.7, short_quantile=0.3, commission=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_alphas(df):\n",
    "    for col in df.columns:\n",
    "        if not col.startswith(\"alpha\"):\n",
    "            continue\n",
    "        if col not in ['alpha21', 'alpha27', 'alpha61', 'alpha62', 'alpha65']:\n",
    "            continue\n",
    "        data = df[[col]].filter(pl.col(col).is_not_null()).to_pandas().to_numpy().astype(np.float64)\n",
    "        print(col)\n",
    "        try:\n",
    "            plt.hist(data.squeeze(), bins=100)\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(data)\n",
    "# plot_alphas(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
