{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polars version: 1.6.0\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import warnings\n",
    "import numpy as np\n",
    "from scipy.stats import kendalltau, rankdata, spearmanr\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from typing import Union, List\n",
    "from tqdm import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "# from eval_utils import calculate_statistics\n",
    "print(f\"Polars version: {pl.__version__}\")\n",
    "\n",
    "from eval_utils import calculate_statistics, plot_array\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_file_path = \"data/linear_compound_factor.parquet\"\n",
    "factor_file_path = \"data/result_hour_alpha101.parquet\"\n",
    "# factor_file_path = \"data/linear_compound_factor_boris.parquet\"\n",
    "factor_data = pl.read_parquet(factor_file_path)\n",
    "\n",
    "# only derive single factor\n",
    "factor_data = factor_data.select([\n",
    "    col for col in factor_data.columns \n",
    "    if 'compound' not in col.lower()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "factor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def smooth_factor_once(input_df: pl.DataFrame, column_name: str, window: int = 20, lag: int = 1, method: str = 'mean', custom_func=None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    对输入的Polars DataFrame的指定列进行平滑处理，使用动态扩展窗口策略。\n",
    "    \n",
    "    参数:\n",
    "    input_df (pl.DataFrame): 输入的Polars DataFrame\n",
    "    column_name (str): 要处理的列名\n",
    "    window (int): 最大滑动窗口大小，默认为20\n",
    "    method (str): 平滑方法，可选 'mean', 'std', 'median', 'min', 'max', 'custom', 'ema', 'zscore', 'skew', 'kurtosis', 'iqr'\n",
    "    custom_func (callable, optional): 自定义的滚动窗口函数，当 method='custom' 时使用\n",
    "    \n",
    "    返回:\n",
    "    pl.DataFrame: 包含新增平滑列的DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    new_column_name = f\"rolling_{column_name}_{method}_{window}\"\n",
    "    window_expr = pl.col(\"\").count().over(\"\").clip(1, window)\n",
    "\n",
    "\n",
    "    if method == 'custom':\n",
    "        if custom_func is None:\n",
    "            raise ValueError(\"当 method='custom' 时，必须提供 custom_func\")\n",
    "        smooth_expr = pl.col(column_name).rolling_apply(custom_func, window_expr, min_periods=1)\n",
    "    elif method == 'ema':\n",
    "        smooth_expr = pl.col(column_name).ewm_mean(span=window, min_periods=1)\n",
    "    elif method == 'zscore':\n",
    "        smooth_expr = (pl.col(column_name) - pl.col(column_name).rolling_mean(window_expr, min_periods=1)) / pl.col(column_name).rolling_std(window_expr, min_periods=1)\n",
    "    elif method in ['skew', 'kurtosis', 'iqr']:\n",
    "        if method == 'skew':\n",
    "            func = lambda x: stats.skew(x, nan_policy='omit')\n",
    "        elif method == 'kurtosis':\n",
    "            func = lambda x: stats.kurtosis(x, nan_policy='omit')\n",
    "        else:  # iqr\n",
    "            func = lambda x: np.percentile(x, 75) - np.percentile(x, 25)\n",
    "        smooth_expr = pl.col(column_name).rolling_apply(func, window_expr, min_periods=1)\n",
    "    elif method in ['mean', 'std', 'median', 'min', 'max', 'sum', 'var']:\n",
    "        # 使用之前的逻辑处理标准方法\n",
    "        smooth_expr = getattr(pl.col(column_name), f\"rolling_{method}\")(window, min_periods=1)\n",
    "    elif method == 'quantile':\n",
    "            # interpolation 参数决定了在计算分位数时的插值方法，常用的值包括：\n",
    "            # \"linear\": 线性插值。\n",
    "            # \"lower\": 使用较低的数据点。\n",
    "            # \"higher\": 使用较高的数据点。\n",
    "            # \"nearest\": 使用最接近的数据点。\n",
    "            # \"midpoint\": 使用中点的值。\n",
    "        smooth_expr = pl.col(column_name).rolling_quantile(0.5, interpolation='linear', window_size = window, min_periods=1)\n",
    "    elif method == 'self_covariance':\n",
    "        assert (0), f'todo'\n",
    "        lagged_col = pl.col(column_name).shift(lag)\n",
    "        smooth_expr = pl.col(column_name).rolling_cov(lagged_col, window_expr, min_periods=1)\n",
    "    elif method == 'self_correlation':\n",
    "        assert (0), f'todo'\n",
    "        # lagged_col = pl.col(column_name).shift(lag)\n",
    "        # smooth_expr = pl.col(column_name).rolling_corr(lagged_col, window_expr, min_periods=1)\n",
    "        def rolling_corr(x):\n",
    "                if len(x) < 2:\n",
    "                    return float('nan')\n",
    "                return np.corrcoef(x[:-lag], x[lag:])[0, 1]\n",
    "        smooth_expr = pl.col(column_name).rolling_apply(rolling_corr, window_expr, min_periods=1)\n",
    "    elif method == 'mad':  # Mean Absolute Deviation\n",
    "        assert (0), f'todo'\n",
    "        # smooth_expr = pl.col(column_name).rolling_apply(lambda x: np.mean(np.abs(x - np.mean(x))), window, min_periods=1)\n",
    "        smooth_expr = pl.col(column_name).rolling_map(lambda x: float(np.mean(np.abs(x - np.mean(x)))), window, min_periods=1)\n",
    "    else:\n",
    "        raise ValueError(f\"未实现的方法: {method}\")\n",
    "    return input_df.with_columns(smooth_expr.alias(new_column_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def custom_rolling_rank(series: pl.Series, window: int) -> pl.Series:\n",
    "    def rank_window(window: pl.Series) -> float:\n",
    "        ranked = window.rank(method=\"average\", descending=True)\n",
    "        return ranked[ranked.len() - 1]\n",
    "\n",
    "    return series.rolling_map(\n",
    "        function=rank_window,\n",
    "        window_size=window,\n",
    "        min_periods=1\n",
    "    )\n",
    "\n",
    "def smooth_factor(\n",
    "    input_df: pl.DataFrame,\n",
    "    factor_name: str,\n",
    "    window: int = 20,\n",
    "    method: Union[str, List[str], None] = None,\n",
    ") -> pl.DataFrame:\n",
    "    supported_methods = [\"mean\", \"var\", \"std\", \"median\", \"min\", \"max\", \"sum\"]\n",
    "\n",
    "    if method is None:\n",
    "        method = supported_methods\n",
    "    elif isinstance(method, str):\n",
    "        method = [method]\n",
    "\n",
    "    result_df = input_df.group_by(\"symbol\").map_groups(\n",
    "        lambda group: group.sort(\"open_time\").with_columns(\n",
    "            [\n",
    "                pl.col(factor_name)\n",
    "                .rolling_mean(window_size=window, min_periods=1)\n",
    "                .alias(f\"rolling_{factor_name}_mean_{window}\"),\n",
    "                pl.col(factor_name)\n",
    "                .rolling_sum(window_size=window, min_periods=1)\n",
    "                .alias(f\"rolling_{factor_name}_sum_{window}\"),\n",
    "                pl.col(factor_name)\n",
    "                .rolling_std(window_size=window, min_periods=1)\n",
    "                .alias(f\"rolling_{factor_name}_std_{window}\"),\n",
    "                pl.col(factor_name)\n",
    "                .rolling_skew(window_size=window)\n",
    "                .alias(f\"rolling_{factor_name}_skew_{window}\"),\n",
    "                pl.col(factor_name)\n",
    "                .rolling_var(window_size=window, min_periods=1)\n",
    "                .alias(f\"rolling_{factor_name}_var_{window}\"),\n",
    "                pl.col(factor_name)\n",
    "                .rolling_quantile(window_size=window, min_periods=1, quantile=0.5)\n",
    "                .alias(f\"rolling_{factor_name}_quantile_50_{window}\"),\n",
    "                pl.rolling_corr(\n",
    "                    pl.col(factor_name),\n",
    "                    pl.col(factor_name).shift(1),\n",
    "                    window_size=window,\n",
    "                    min_periods=1,\n",
    "                ).alias(f\"rolling_{factor_name}_self_corr_lag1_{window}\"),\n",
    "                pl.rolling_corr(\n",
    "                    pl.col(factor_name),\n",
    "                    pl.col(factor_name).shift(2),\n",
    "                    window_size=window,\n",
    "                    min_periods=1,\n",
    "                ).alias(f\"rolling_{factor_name}_self_corr_lag2_{window}\"),\n",
    "                pl.rolling_cov(\n",
    "                    pl.col(factor_name),\n",
    "                    pl.col(factor_name).shift(1),\n",
    "                    window_size=window,\n",
    "                    min_periods=1,\n",
    "                ).alias(f\"rolling_{factor_name}_self_cov_lag1_{window}\"),\n",
    "                pl.rolling_cov(\n",
    "                    pl.col(factor_name),\n",
    "                    pl.col(factor_name).shift(2),\n",
    "                    window_size=window,\n",
    "                    min_periods=1,\n",
    "                ).alias(f\"rolling_{factor_name}_self_cov_lag2_{window}\"),\n",
    "                pl.col(factor_name)\n",
    "                .ewm_mean(span=window, adjust=True)\n",
    "                .alias(f\"rolling_{factor_name}_ewm_mean_{window}\"),\n",
    "                pl.col(factor_name)\n",
    "                .ewm_std(span=window, adjust=True)\n",
    "                .alias(f\"rolling_{factor_name}_ewm_std_{window}\"),\n",
    "                pl.col(factor_name)\n",
    "                .ewm_var(span=window, adjust=True)\n",
    "                .alias(f\"rolling_{factor_name}_ewm_var_{window}\"),\n",
    "                # range: max - min\n",
    "                (\n",
    "                    pl.col(factor_name).rolling_max(window_size=window, min_periods=1)\n",
    "                    - pl.col(factor_name).rolling_min(window_size=window, min_periods=1)\n",
    "                ).alias(f\"rolling_{factor_name}_range_{window}\"),\n",
    "                # z-score\n",
    "                (\n",
    "                    (\n",
    "                        pl.col(factor_name)\n",
    "                        - pl.col(factor_name).rolling_mean(\n",
    "                            window_size=window, min_periods=1\n",
    "                        )\n",
    "                    )\n",
    "                    / pl.col(factor_name).rolling_std(window_size=window, min_periods=1)\n",
    "                ).alias(f\"rolling_{factor_name}_zscore_{window}\"),\n",
    "                # 差分\n",
    "                pl.col(factor_name).diff().alias(f'{factor_name}_diff_1'),\n",
    "                pl.col(factor_name).diff(2).alias(f'{factor_name}_diff_2'),\n",
    "                # 百分比变化\n",
    "                pl.col(factor_name).pct_change().alias(f'{factor_name}_pct_change_1'),\n",
    "                pl.col(factor_name).pct_change(2).alias(f'{factor_name}_pct_change_2'),\n",
    "                # custom\n",
    "                custom_rolling_rank(pl.col(factor_name), window).alias(f'rolling_{factor_name}_rank_{window}'),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_name = [col for col in factor_data.columns if col not in ['open_time', 'close_time', 'symbol'] and 'auto_corr' not in col]\n",
    "# factor_name = ['open']\n",
    "factor_name = factor_name[:10]\n",
    "print (f'factor_name: {factor_name}')\n",
    "roll_df = factor_data.clone()\n",
    "for each_factor in tqdm(factor_name, desc=\"Processing factors\"):\n",
    "# for each_factor in factor_name:\n",
    "    # roll_df = smooth_factor_once(roll_df, each_factor, window=2, method='ema')\n",
    "    # roll_df = smooth_factor_once(roll_df, each_factor, window=5, method='sum')\n",
    "    # roll_df = smooth_factor_once(roll_df, each_factor, window=2, method='mad')\n",
    "    # roll_df = smooth_factor(roll_df, each_factor, window=20, method = ['var'])\n",
    "    roll_df = smooth_factor(roll_df, each_factor, window=6)\n",
    "    roll_df = smooth_factor(roll_df, each_factor, window=20)\n",
    "    roll_df = smooth_factor(roll_df, each_factor, window=40)\n",
    "    # roll_df = smooth_factor_once(roll_df, each_factor, window=20, method='mean')\n",
    "    # break\n",
    "    # roll_df = smooth_factor(roll_df, each_factor, window=20, method='std')\n",
    "\n",
    "roll_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (230_723, 2_388)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>symbol</th><th>open_time</th><th>close_time</th><th>close</th><th>volume</th><th>count</th><th>return</th><th>amihud</th><th>return_skew</th><th>return_kurtosis</th><th>alpha13</th><th>alpha15</th><th>alpha16</th><th>alpha24</th><th>alpha25</th><th>alpha26</th><th>alpha28</th><th>alpha30</th><th>alpha34</th><th>alpha35</th><th>alpha36</th><th>alpha38</th><th>alpha40</th><th>alpha44</th><th>alpha45</th><th>alpha46</th><th>alpha47</th><th>alpha50</th><th>alpha51</th><th>alpha54</th><th>alpha55</th><th>alpha62</th><th>alpha64</th><th>alpha71</th><th>alpha74</th><th>alpha81</th><th>alpha94</th><th>&hellip;</th><th>quote_volume_market_share_pct_diff_1</th><th>quote_volume_market_share_pct_diff_2</th><th>quote_volume_market_share_pct_pct_change_1</th><th>quote_volume_market_share_pct_pct_change_2</th><th>rolling_quote_volume_market_share_pct_rank_6</th><th>rolling_quote_volume_market_share_pct_mean_20</th><th>rolling_quote_volume_market_share_pct_sum_20</th><th>rolling_quote_volume_market_share_pct_std_20</th><th>rolling_quote_volume_market_share_pct_skew_20</th><th>rolling_quote_volume_market_share_pct_var_20</th><th>rolling_quote_volume_market_share_pct_quantile_50_20</th><th>rolling_quote_volume_market_share_pct_self_corr_lag1_20</th><th>rolling_quote_volume_market_share_pct_self_corr_lag2_20</th><th>rolling_quote_volume_market_share_pct_self_cov_lag1_20</th><th>rolling_quote_volume_market_share_pct_self_cov_lag2_20</th><th>rolling_quote_volume_market_share_pct_ewm_mean_20</th><th>rolling_quote_volume_market_share_pct_ewm_std_20</th><th>rolling_quote_volume_market_share_pct_ewm_var_20</th><th>rolling_quote_volume_market_share_pct_range_20</th><th>rolling_quote_volume_market_share_pct_zscore_20</th><th>rolling_quote_volume_market_share_pct_rank_20</th><th>rolling_quote_volume_market_share_pct_mean_40</th><th>rolling_quote_volume_market_share_pct_sum_40</th><th>rolling_quote_volume_market_share_pct_std_40</th><th>rolling_quote_volume_market_share_pct_skew_40</th><th>rolling_quote_volume_market_share_pct_var_40</th><th>rolling_quote_volume_market_share_pct_quantile_50_40</th><th>rolling_quote_volume_market_share_pct_self_corr_lag1_40</th><th>rolling_quote_volume_market_share_pct_self_corr_lag2_40</th><th>rolling_quote_volume_market_share_pct_self_cov_lag1_40</th><th>rolling_quote_volume_market_share_pct_self_cov_lag2_40</th><th>rolling_quote_volume_market_share_pct_ewm_mean_40</th><th>rolling_quote_volume_market_share_pct_ewm_std_40</th><th>rolling_quote_volume_market_share_pct_ewm_var_40</th><th>rolling_quote_volume_market_share_pct_range_40</th><th>rolling_quote_volume_market_share_pct_zscore_40</th><th>rolling_quote_volume_market_share_pct_rank_40</th></tr><tr><td>str</td><td>datetime[ms]</td><td>datetime[ms]</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>i64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;WAVESUSDT&quot;</td><td>2020-08-12 00:00:00</td><td>2020-08-12 23:59:59.999</td><td>2.169</td><td>2.2259e7</td><td>121054</td><td>0.0</td><td>0.0</td><td>NaN</td><td>NaN</td><td>-0.001773</td><td>-0.921434</td><td>-0.001755</td><td>-2.0804</td><td>0.497414</td><td>-0.0</td><td>-5.1585e-7</td><td>0.178982</td><td>0.317386</td><td>300.0</td><td>3.023907</td><td>-0.015818</td><td>0.533451</td><td>0.997737</td><td>0.132855</td><td>-2.0804</td><td>-0.24872</td><td>-0.931393</td><td>-2.0804</td><td>-1.192573</td><td>0.974516</td><td>0</td><td>-1</td><td>0.0</td><td>0</td><td>0</td><td>-0.327235</td><td>&hellip;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1.0</td><td>0.777309</td><td>0.777309</td><td>null</td><td>null</td><td>null</td><td>0.777309</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.777309</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>1.0</td><td>0.777309</td><td>0.777309</td><td>null</td><td>null</td><td>null</td><td>0.777309</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.777309</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>1.0</td></tr><tr><td>&quot;WAVESUSDT&quot;</td><td>2020-08-13 00:00:00</td><td>2020-08-13 23:59:59.999</td><td>3.3433</td><td>6.5613e7</td><td>511154</td><td>54.140157</td><td>0.0</td><td>NaN</td><td>NaN</td><td>-0.001543</td><td>-0.821704</td><td>-0.001521</td><td>-3.2547</td><td>0.003368</td><td>-0.0</td><td>-8.5045e-7</td><td>0.067527</td><td>0.03922</td><td>930.0</td><td>0.952982</td><td>-0.787594</td><td>0.60436</td><td>0.822964</td><td>-0.139378</td><td>-1.0</td><td>-0.384068</td><td>-0.465718</td><td>-1.1743</td><td>-0.093413</td><td>0.929627</td><td>0</td><td>-1</td><td>0.0</td><td>0</td><td>0</td><td>-0.452243</td><td>&hellip;</td><td>1.48603</td><td>null</td><td>1.911764</td><td>null</td><td>1.0</td><td>1.520324</td><td>3.040647</td><td>1.050782</td><td>null</td><td>1.104143</td><td>2.263339</td><td>NaN</td><td>null</td><td>NaN</td><td>null</td><td>1.557474</td><td>1.050782</td><td>1.104143</td><td>1.48603</td><td>0.707107</td><td>1.0</td><td>1.520324</td><td>3.040647</td><td>1.050782</td><td>null</td><td>1.104143</td><td>2.263339</td><td>NaN</td><td>null</td><td>NaN</td><td>null</td><td>1.538899</td><td>1.050782</td><td>1.104143</td><td>1.48603</td><td>0.707107</td><td>1.0</td></tr><tr><td>&quot;WAVESUSDT&quot;</td><td>2020-08-14 00:00:00</td><td>2020-08-14 23:59:59.999</td><td>3.505</td><td>4.8895e7</td><td>469609</td><td>4.836539</td><td>0.0</td><td>NaN</td><td>NaN</td><td>-0.001599</td><td>-0.749431</td><td>-0.001586</td><td>-3.4164</td><td>0.011174</td><td>0.666667</td><td>-4.9450e-7</td><td>0.008498</td><td>0.065373</td><td>728.0</td><td>1.253999</td><td>-0.783944</td><td>0.688842</td><td>0.770302</td><td>0.139503</td><td>-1.0</td><td>-0.515913</td><td>-0.357465</td><td>-0.1617</td><td>-0.325404</td><td>0.933671</td><td>0</td><td>-1</td><td>0.0</td><td>0</td><td>0</td><td>-0.262461</td><td>&hellip;</td><td>0.568797</td><td>2.054827</td><td>0.251309</td><td>2.643515</td><td>1.0</td><td>1.957594</td><td>5.872783</td><td>1.060985</td><td>null</td><td>1.125688</td><td>2.263339</td><td>1.0</td><td>NaN</td><td>0.422625</td><td>NaN</td><td>2.025522</td><td>1.045304</td><td>1.092661</td><td>2.054827</td><td>0.824273</td><td>1.0</td><td>1.957594</td><td>5.872783</td><td>1.060985</td><td>null</td><td>1.125688</td><td>2.263339</td><td>1.0</td><td>NaN</td><td>0.422625</td><td>NaN</td><td>1.991707</td><td>1.053364</td><td>1.109575</td><td>2.054827</td><td>0.824273</td><td>1.0</td></tr><tr><td>&quot;WAVESUSDT&quot;</td><td>2020-08-15 00:00:00</td><td>2020-08-15 23:59:59.999</td><td>3.399</td><td>2.6652e7</td><td>231202</td><td>-3.024251</td><td>0.0</td><td>1.681406</td><td>-1.5</td><td>-0.001989</td><td>-1.024367</td><td>-0.001976</td><td>-3.3104</td><td>0.945185</td><td>0.322749</td><td>-5.0204e-7</td><td>0.02957</td><td>0.958114</td><td>260.0</td><td>2.318267</td><td>-0.227765</td><td>0.754355</td><td>0.692007</td><td>-0.138159</td><td>-1.0</td><td>-0.600473</td><td>-0.357465</td><td>0.106</td><td>-0.383057</td><td>0.9062</td><td>0</td><td>-1</td><td>0.0</td><td>0</td><td>0</td><td>-0.536565</td><td>&hellip;</td><td>-1.46279</td><td>-0.893993</td><td>-0.516497</td><td>-0.394989</td><td>3.0</td><td>1.810532</td><td>7.242128</td><td>0.91486</td><td>null</td><td>0.836968</td><td>2.263339</td><td>-0.388519</td><td>-1.0</td><td>-0.303964</td><td>-1.086875</td><td>1.836094</td><td>0.899901</td><td>0.809822</td><td>2.054827</td><td>-0.482245</td><td>3.0</td><td>1.810532</td><td>7.242128</td><td>0.91486</td><td>null</td><td>0.836968</td><td>2.263339</td><td>-0.388519</td><td>-1.0</td><td>-0.303964</td><td>-1.086875</td><td>1.824258</td><td>0.907053</td><td>0.822745</td><td>2.054827</td><td>-0.482245</td><td>3.0</td></tr><tr><td>&quot;WAVESUSDT&quot;</td><td>2020-08-16 00:00:00</td><td>2020-08-16 23:59:59.999</td><td>4.0495</td><td>3.4530e7</td><td>426109</td><td>19.137982</td><td>0.0</td><td>1.914915</td><td>3.705905</td><td>-0.980136</td><td>-1.507557</td><td>-0.966695</td><td>-3.9609</td><td>0.009701</td><td>-0.0</td><td>-6.6882e-7</td><td>0.012597</td><td>0.217296</td><td>1350.0</td><td>1.145454</td><td>-0.77939</td><td>0.782476</td><td>-0.501783</td><td>-0.139852</td><td>-1.0</td><td>-0.627125</td><td>-0.530143</td><td>-0.6505</td><td>-0.296826</td><td>0.852072</td><td>0</td><td>-1</td><td>0.0</td><td>0</td><td>0</td><td>-0.565948</td><td>&hellip;</td><td>0.917416</td><td>-0.545374</td><td>0.669967</td><td>-0.192566</td><td>2.0</td><td>1.905778</td><td>9.52889</td><td>0.820418</td><td>null</td><td>0.673085</td><td>2.263339</td><td>-0.400694</td><td>-0.589167</td><td>-0.222029</td><td>-0.462096</td><td>1.945107</td><td>0.789194</td><td>0.622828</td><td>2.054827</td><td>0.464378</td><td>2.0</td><td>1.905778</td><td>9.52889</td><td>0.820418</td><td>null</td><td>0.673085</td><td>2.263339</td><td>-0.400694</td><td>-0.589167</td><td>-0.222029</td><td>-0.462096</td><td>1.926234</td><td>0.804609</td><td>0.647396</td><td>2.054827</td><td>0.464378</td><td>2.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;ONEUSDT&quot;</td><td>2024-07-31 00:00:00</td><td>2024-07-31 23:59:59.999</td><td>0.01311</td><td>3.36746823e8</td><td>39837</td><td>-3.532009</td><td>8.1709e-7</td><td>1.084441</td><td>8.706674</td><td>-0.532271</td><td>-1.757822</td><td>-0.300959</td><td>-0.00115</td><td>0.594017</td><td>-0.272166</td><td>4.0321e-8</td><td>0.152624</td><td>0.782062</td><td>-0.0</td><td>2.472668</td><td>-0.049905</td><td>0.005085</td><td>-0.0</td><td>0.0</td><td>1.0</td><td>-0.14208</td><td>-0.789129</td><td>0.00048</td><td>-0.026599</td><td>-0.187959</td><td>0</td><td>-1</td><td>4.0</td><td>0</td><td>0</td><td>0.0</td><td>&hellip;</td><td>0.000543</td><td>0.001564</td><td>0.050689</td><td>0.161385</td><td>2.0</td><td>0.012361</td><td>0.247222</td><td>0.002358</td><td>2.185106</td><td>0.000006</td><td>0.012084</td><td>0.045902</td><td>-0.213878</td><td>2.5484e-7</td><td>-0.000001</td><td>0.012223</td><td>0.002309</td><td>0.000005</td><td>0.010859</td><td>-0.469501</td><td>14.0</td><td>0.013053</td><td>0.522123</td><td>0.002152</td><td>1.128543</td><td>0.000005</td><td>0.01258</td><td>0.198469</td><td>-0.091639</td><td>9.2548e-7</td><td>-4.2376e-7</td><td>0.013532</td><td>0.00422</td><td>0.000018</td><td>0.010859</td><td>-0.835982</td><td>33.0</td></tr><tr><td>&quot;ONEUSDT&quot;</td><td>2024-08-01 00:00:00</td><td>2024-08-01 23:59:59.999</td><td>0.01313</td><td>5.61881623e8</td><td>52867</td><td>0.152555</td><td>6.7583e-7</td><td>1.08568</td><td>8.712784</td><td>-0.256134</td><td>-0.964312</td><td>-0.101496</td><td>-0.00117</td><td>0.491344</td><td>-0.272166</td><td>-1.5923e-8</td><td>0.167483</td><td>0.540746</td><td>476.0</td><td>2.057779</td><td>-0.044507</td><td>0.011827</td><td>-0.0</td><td>0.0</td><td>1.0</td><td>-0.192472</td><td>-0.789129</td><td>-0.00002</td><td>-0.890016</td><td>-0.018898</td><td>0</td><td>-1</td><td>4.0</td><td>0</td><td>0</td><td>0.0</td><td>&hellip;</td><td>0.001764</td><td>0.002307</td><td>0.156737</td><td>0.215371</td><td>2.0</td><td>0.012382</td><td>0.247638</td><td>0.002362</td><td>2.147826</td><td>0.000006</td><td>0.012084</td><td>0.036459</td><td>-0.221368</td><td>2.0307e-7</td><td>-0.000001</td><td>0.012299</td><td>0.002209</td><td>0.000005</td><td>0.010859</td><td>0.269252</td><td>6.0</td><td>0.013012</td><td>0.520498</td><td>0.002137</td><td>1.200358</td><td>0.000005</td><td>0.01258</td><td>0.179591</td><td>-0.107349</td><td>8.2575e-7</td><td>-4.9697e-7</td><td>0.013507</td><td>0.004117</td><td>0.000017</td><td>0.010859</td><td>0.002557</td><td>17.0</td></tr><tr><td>&quot;ONEUSDT&quot;</td><td>2024-08-02 00:00:00</td><td>2024-08-02 23:59:59.999</td><td>0.01213</td><td>5.24499687e8</td><td>54106</td><td>-7.616146</td><td>7.6960e-7</td><td>1.086088</td><td>8.722216</td><td>-0.211114</td><td>-0.41679</td><td>-0.096364</td><td>-0.00017</td><td>0.654401</td><td>0.045835</td><td>-7.4262e-8</td><td>0.187669</td><td>0.344094</td><td>-0.0</td><td>1.767522</td><td>-0.01705</td><td>0.018759</td><td>-0.0</td><td>0.0</td><td>1.0</td><td>-0.067691</td><td>-0.591382</td><td>0.001</td><td>-0.181911</td><td>0.318925</td><td>0</td><td>-1</td><td>6.0</td><td>0</td><td>0</td><td>0.0</td><td>&hellip;</td><td>-0.001905</td><td>-0.000141</td><td>-0.146306</td><td>-0.0125</td><td>4.0</td><td>0.012333</td><td>0.246667</td><td>0.002378</td><td>2.15856</td><td>0.000006</td><td>0.012053</td><td>0.0292</td><td>-0.203351</td><td>1.6405e-7</td><td>-0.000001</td><td>0.012186</td><td>0.002131</td><td>0.000005</td><td>0.010859</td><td>-0.512951</td><td>14.0</td><td>0.012896</td><td>0.515825</td><td>0.002109</td><td>1.339237</td><td>0.000004</td><td>0.01258</td><td>0.15749</td><td>-0.129195</td><td>7.0949e-7</td><td>-5.8624e-7</td><td>0.01339</td><td>0.004049</td><td>0.000016</td><td>0.010859</td><td>-0.845272</td><td>33.0</td></tr><tr><td>&quot;ONEUSDT&quot;</td><td>2024-08-03 00:00:00</td><td>2024-08-03 23:59:59.999</td><td>0.01135</td><td>4.49787626e8</td><td>41948</td><td>-6.430338</td><td>7.8529e-7</td><td>1.086434</td><td>8.712854</td><td>-0.212449</td><td>-0.892663</td><td>-0.096065</td><td>-0.0</td><td>0.635433</td><td>0.045835</td><td>-1.0399e-7</td><td>0.192041</td><td>0.814201</td><td>-0.0</td><td>1.782878</td><td>-0.009055</td><td>0.022396</td><td>-0.0</td><td>0.0</td><td>1.0</td><td>-0.109594</td><td>-0.47062</td><td>0.00078</td><td>-0.265619</td><td>0.239846</td><td>0</td><td>-1</td><td>8.0</td><td>0</td><td>0</td><td>0.0</td><td>&hellip;</td><td>0.000686</td><td>-0.001219</td><td>0.061717</td><td>-0.093618</td><td>2.0</td><td>0.012248</td><td>0.244961</td><td>0.002365</td><td>2.300194</td><td>0.000006</td><td>0.011878</td><td>0.037997</td><td>-0.209806</td><td>2.1371e-7</td><td>-0.000001</td><td>0.012149</td><td>0.00203</td><td>0.000004</td><td>0.010859</td><td>-0.189799</td><td>11.0</td><td>0.012881</td><td>0.515257</td><td>0.002114</td><td>1.345889</td><td>0.000004</td><td>0.01258</td><td>0.179199</td><td>-0.124929</td><td>7.9880e-7</td><td>-5.6429e-7</td><td>0.013312</td><td>0.003964</td><td>0.000016</td><td>0.010859</td><td>-0.511905</td><td>29.0</td></tr><tr><td>&quot;ONEUSDT&quot;</td><td>2024-08-04 00:00:00</td><td>2024-08-04 23:59:59.999</td><td>0.01062</td><td>5.41335395e8</td><td>45761</td><td>-6.431718</td><td>8.9312e-7</td><td>1.087294</td><td>8.709148</td><td>-0.243816</td><td>-1.137216</td><td>-0.124667</td><td>-0.0</td><td>0.647492</td><td>-0.0</td><td>-1.1925e-7</td><td>0.286577</td><td>0.908041</td><td>-0.0</td><td>1.46821</td><td>-0.008864</td><td>0.033512</td><td>-0.0</td><td>0.0</td><td>1.0</td><td>-0.064354</td><td>-0.41567</td><td>0.00073</td><td>-0.203783</td><td>0.222012</td><td>0</td><td>-1</td><td>7.0</td><td>0</td><td>0</td><td>0.0</td><td>&hellip;</td><td>-0.000171</td><td>0.000515</td><td>-0.014499</td><td>0.046324</td><td>3.0</td><td>0.012253</td><td>0.245053</td><td>0.002363</td><td>2.298698</td><td>0.000006</td><td>0.011878</td><td>0.049295</td><td>-0.203063</td><td>2.7551e-7</td><td>-0.000001</td><td>0.0121</td><td>0.001938</td><td>0.000004</td><td>0.010859</td><td>-0.264248</td><td>12.0</td><td>0.012908</td><td>0.516317</td><td>0.002091</td><td>1.382303</td><td>0.000004</td><td>0.01258</td><td>0.181676</td><td>-0.076101</td><td>8.0306e-7</td><td>-3.3550e-7</td><td>0.01323</td><td>0.003884</td><td>0.000015</td><td>0.010859</td><td>-0.612084</td><td>30.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (230_723, 2_388)\n",
       "┌───────────┬────────────┬───────────┬─────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ symbol    ┆ open_time  ┆ close_tim ┆ close   ┆ … ┆ rolling_q ┆ rolling_q ┆ rolling_q ┆ rolling_q │\n",
       "│ ---       ┆ ---        ┆ e         ┆ ---     ┆   ┆ uote_volu ┆ uote_volu ┆ uote_volu ┆ uote_volu │\n",
       "│ str       ┆ datetime[m ┆ ---       ┆ f64     ┆   ┆ me_market ┆ me_market ┆ me_market ┆ me_market │\n",
       "│           ┆ s]         ┆ datetime[ ┆         ┆   ┆ _sh…      ┆ _sh…      ┆ _sh…      ┆ _sh…      │\n",
       "│           ┆            ┆ ms]       ┆         ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│           ┆            ┆           ┆         ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞═══════════╪════════════╪═══════════╪═════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ WAVESUSDT ┆ 2020-08-12 ┆ 2020-08-1 ┆ 2.169   ┆ … ┆ 0.0       ┆ 0.0       ┆ null      ┆ 1.0       │\n",
       "│           ┆ 00:00:00   ┆ 2 23:59:5 ┆         ┆   ┆           ┆           ┆           ┆           │\n",
       "│           ┆            ┆ 9.999     ┆         ┆   ┆           ┆           ┆           ┆           │\n",
       "│ WAVESUSDT ┆ 2020-08-13 ┆ 2020-08-1 ┆ 3.3433  ┆ … ┆ 1.104143  ┆ 1.48603   ┆ 0.707107  ┆ 1.0       │\n",
       "│           ┆ 00:00:00   ┆ 3 23:59:5 ┆         ┆   ┆           ┆           ┆           ┆           │\n",
       "│           ┆            ┆ 9.999     ┆         ┆   ┆           ┆           ┆           ┆           │\n",
       "│ WAVESUSDT ┆ 2020-08-14 ┆ 2020-08-1 ┆ 3.505   ┆ … ┆ 1.109575  ┆ 2.054827  ┆ 0.824273  ┆ 1.0       │\n",
       "│           ┆ 00:00:00   ┆ 4 23:59:5 ┆         ┆   ┆           ┆           ┆           ┆           │\n",
       "│           ┆            ┆ 9.999     ┆         ┆   ┆           ┆           ┆           ┆           │\n",
       "│ WAVESUSDT ┆ 2020-08-15 ┆ 2020-08-1 ┆ 3.399   ┆ … ┆ 0.822745  ┆ 2.054827  ┆ -0.482245 ┆ 3.0       │\n",
       "│           ┆ 00:00:00   ┆ 5 23:59:5 ┆         ┆   ┆           ┆           ┆           ┆           │\n",
       "│           ┆            ┆ 9.999     ┆         ┆   ┆           ┆           ┆           ┆           │\n",
       "│ WAVESUSDT ┆ 2020-08-16 ┆ 2020-08-1 ┆ 4.0495  ┆ … ┆ 0.647396  ┆ 2.054827  ┆ 0.464378  ┆ 2.0       │\n",
       "│           ┆ 00:00:00   ┆ 6 23:59:5 ┆         ┆   ┆           ┆           ┆           ┆           │\n",
       "│           ┆            ┆ 9.999     ┆         ┆   ┆           ┆           ┆           ┆           │\n",
       "│ …         ┆ …          ┆ …         ┆ …       ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ ONEUSDT   ┆ 2024-07-31 ┆ 2024-07-3 ┆ 0.01311 ┆ … ┆ 0.000018  ┆ 0.010859  ┆ -0.835982 ┆ 33.0      │\n",
       "│           ┆ 00:00:00   ┆ 1 23:59:5 ┆         ┆   ┆           ┆           ┆           ┆           │\n",
       "│           ┆            ┆ 9.999     ┆         ┆   ┆           ┆           ┆           ┆           │\n",
       "│ ONEUSDT   ┆ 2024-08-01 ┆ 2024-08-0 ┆ 0.01313 ┆ … ┆ 0.000017  ┆ 0.010859  ┆ 0.002557  ┆ 17.0      │\n",
       "│           ┆ 00:00:00   ┆ 1 23:59:5 ┆         ┆   ┆           ┆           ┆           ┆           │\n",
       "│           ┆            ┆ 9.999     ┆         ┆   ┆           ┆           ┆           ┆           │\n",
       "│ ONEUSDT   ┆ 2024-08-02 ┆ 2024-08-0 ┆ 0.01213 ┆ … ┆ 0.000016  ┆ 0.010859  ┆ -0.845272 ┆ 33.0      │\n",
       "│           ┆ 00:00:00   ┆ 2 23:59:5 ┆         ┆   ┆           ┆           ┆           ┆           │\n",
       "│           ┆            ┆ 9.999     ┆         ┆   ┆           ┆           ┆           ┆           │\n",
       "│ ONEUSDT   ┆ 2024-08-03 ┆ 2024-08-0 ┆ 0.01135 ┆ … ┆ 0.000016  ┆ 0.010859  ┆ -0.511905 ┆ 29.0      │\n",
       "│           ┆ 00:00:00   ┆ 3 23:59:5 ┆         ┆   ┆           ┆           ┆           ┆           │\n",
       "│           ┆            ┆ 9.999     ┆         ┆   ┆           ┆           ┆           ┆           │\n",
       "│ ONEUSDT   ┆ 2024-08-04 ┆ 2024-08-0 ┆ 0.01062 ┆ … ┆ 0.000015  ┆ 0.010859  ┆ -0.612084 ┆ 30.0      │\n",
       "│           ┆ 00:00:00   ┆ 4 23:59:5 ┆         ┆   ┆           ┆           ┆           ┆           │\n",
       "│           ┆            ┆ 9.999     ┆         ┆   ┆           ┆           ┆           ┆           │\n",
       "└───────────┴────────────┴───────────┴─────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 1:\n",
    "    roll_df = pl.read_parquet ('data/rolling_factors.parquet')\n",
    "roll_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FactorStatResult:\n",
    "    def __init__(self, ann_return, sharpe, maxdd, calmar_ratio):\n",
    "        self.ann_return = ann_return\n",
    "        self.sharpe = sharpe\n",
    "        self.maxdd = maxdd\n",
    "        self.calmar_ratio = calmar_ratio\n",
    "\n",
    "def factor_stats(n, pnl:pl.Series):\n",
    "    net_value = pnl.cum_sum() + 1.0\n",
    "    sharpe = n ** 0.5 * pnl.mean() / pnl.std()\n",
    "    ann_return = n * pnl.mean()\n",
    "    maxdd = (-(net_value / net_value.cum_max() - 1)).max()\n",
    "    if maxdd == 0:\n",
    "        # print (f'net_value: {net_value} ===')\n",
    "        # print (f'pnl: ==== {pnl}')\n",
    "        # # Plot the trend of pnl\n",
    "        # plt.figure(figsize=(10, 6))\n",
    "        # plt.plot(pnl.cum_sum().to_numpy())\n",
    "        # plt.title(f'Cumulative PnL Trend (n={n})')\n",
    "        # plt.xlabel('Time')\n",
    "        # plt.ylabel('Cumulative PnL')\n",
    "        # plt.grid(True)\n",
    "        # plt.show()\n",
    "        print(\"警告：检测到零回撤\")\n",
    "        # 使用一个很小的非零值作为替代\n",
    "        maxdd = 1e-6 \n",
    "\n",
    "    calmar_ratio = ann_return / maxdd\n",
    "    return FactorStatResult(ann_return, sharpe, maxdd, calmar_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_single_factor(input_df: pl.DataFrame, factor_name: str):\n",
    "    FACTOR_NAME = factor_name\n",
    "    # print ('FACTOR_NAME:', FACTOR_NAME)\n",
    "\n",
    "    close = input_df[[\"open_time\", \"symbol\", \"close\"]].pivot(index=\"open_time\", columns=\"symbol\", values=\"close\").sort(\"open_time\")\n",
    "    factors = input_df[[\"open_time\", \"symbol\", FACTOR_NAME]].pivot(index=\"open_time\", columns=\"symbol\", values = FACTOR_NAME).sort(\"open_time\")\n",
    "\n",
    "    symbol_list = close.columns[1:]\n",
    "    # print ('factors shape:', factors.shape)\n",
    "    # factors.fill_nan(0).describe()\n",
    "    factors.describe()\n",
    "\n",
    "    # 因子未来收益率：\n",
    "    ret = close.clone()\n",
    "    ret[symbol_list] = ret[symbol_list].shift(-1) / ret[symbol_list] - 1\n",
    "\n",
    "    # 对齐column\n",
    "    ret = ret[factors.columns] \n",
    "    t = factors[[\"open_time\"]] \n",
    "\n",
    "    # 对齐open_time\n",
    "    ret = ret.join(t, how=\"inner\", on=[\"open_time\"]).sort(by=[\"open_time\"]) \n",
    "    factors = factors.sort(by=[\"open_time\"])\n",
    "\n",
    "\n",
    "    factors_np = factors[symbol_list].to_numpy()\n",
    "    ret_np = ret[symbol_list].to_numpy()\n",
    "    num_timestamps = factors_np.shape[0]\n",
    "    num_stocks = factors_np.shape[1]\n",
    "\n",
    "    # Initialize an array to store the IC values\n",
    "    ic_values = np.zeros(num_timestamps)\n",
    "    rank_ic_values = np.zeros(num_timestamps)\n",
    "\n",
    "    for i in range(num_timestamps):\n",
    "        # Extract the factor values and return values for the current timestamp\n",
    "        factor_values = factors_np[i, :]\n",
    "        returns = ret_np[i, :]\n",
    "\n",
    "        # Find indices where both factor_values and returns are not NaN\n",
    "        valid_indices = ~(np.isnan(factor_values) | np.isnan(returns))\n",
    "\n",
    "        # Filter out NaN values\n",
    "        factor_values_valid = factor_values[valid_indices]\n",
    "        returns_valid = returns[valid_indices]\n",
    "\n",
    "        # Rank the valid arrays\n",
    "        ranked_factors = rankdata(factor_values_valid)\n",
    "        ranked_returns = rankdata(returns_valid)\n",
    "\n",
    "        # Calculate the Pearson correlation coefficient (IC)\n",
    "        if len(factor_values_valid) > 1:\n",
    "            if 0:\n",
    "                ic_values[i] = np.corrcoef(factor_values_valid, returns_valid)[0, 1]\n",
    "                rank_ic_values[i] = np.corrcoef(ranked_factors, ranked_returns)[0, 1]\n",
    "            elif 0:\n",
    "                ic_values[i] = spearmanr(factor_values_valid, returns_valid).correlation\n",
    "                rank_ic_values[i] = spearmanr(ranked_factors, ranked_returns).correlation\n",
    "            else:\n",
    "                tau, _ = kendalltau(factor_values_valid, returns_valid)\n",
    "                rank_tau, _ = kendalltau(ranked_factors, ranked_returns)\n",
    "                # print (f'tau: {tau} == factor_values: {factor_values_valid} == returns: {returns_valid}')\n",
    "                ic_values[i] = tau\n",
    "                rank_ic_values[i] = rank_tau\n",
    "        else:\n",
    "            ic_values[i] = np.nan\n",
    "\n",
    "    # print_statistics(ic_values, \"IC\")\n",
    "    ic_stat: dict = calculate_statistics (ic_values)\n",
    "    # print ('ic stat dict', ic_stat)\n",
    "    # plot_array(f\"{FACTOR_NAME} IC result\", ic_values, cumulative = False)\n",
    "    # plot_array(f\"{FACTOR_NAME} IC result\", ic_values, cumulative = True)\n",
    "\n",
    "    # print_statistics(rank_ic_values, \"Rank IC\")\n",
    "    rank_ic_stat: dict = calculate_statistics (rank_ic_values)\n",
    "    # print ('rank ic stat dict', rank_ic_stat)\n",
    "    # plot_array(f\"{FACTOR_NAME} Rank IC result\", rank_ic_values, cumulative = False)\n",
    "    # plot_array(f\"{FACTOR_NAME} Rank IC result\", rank_ic_values, cumulative = True)\n",
    "\n",
    "    \n",
    "    # calc sharp ratio\n",
    "    # 求每一行的分位数\n",
    "    commission = 5/100000 \n",
    "    percentage = 0.5\n",
    "    quantiles = np.nanquantile(factors_np, [1 - percentage, percentage], axis=1)\n",
    "\n",
    "    # 把quantiles[0]和[1]变成factors_np的shape\n",
    "    f = lambda x: quantiles[x][:, None].repeat(factors_np.shape[1], axis=-1)\n",
    "    long_quantile, short_quantile = f(0), f(1)\n",
    "\n",
    "    # print (f'quantiles: {quantiles} .  long_quantile: {long_quantile}, short_quantile: {short_quantile}')\n",
    "\n",
    "    # return before fee\n",
    "    long = np.nan_to_num(np.nan_to_num(ret_np * (factors_np > long_quantile), 0.0).sum(axis=1) / (factors_np > long_quantile).sum(axis=1) , 0.0)\n",
    "    short = np.nan_to_num(np.nan_to_num(ret_np * (factors_np < long_quantile), 0.0).sum(axis=1) / (factors_np < long_quantile).sum(axis=1) , 0.0)\n",
    "    bench = np.nan_to_num(np.nanmean(ret_np, axis=1), 0.0)\n",
    "\n",
    "    # return after fee\n",
    "    long_fee = pl.Series(long - 2 * commission)\n",
    "    short_fee = pl.Series(short - 2 * commission)\n",
    "    bench_fee = pl.Series(bench - 2 * commission)\n",
    "\n",
    "    long_short = pl.Series(long - short - 2 * commission)\n",
    "    long_bench = pl.Series(long - bench - 2 * commission)\n",
    "    bench_short = pl.Series(bench - short - 2 * commission)\n",
    "    bench_long = pl.Series(bench - long - 2 * commission)\n",
    "    short_long = pl.Series(short - long - 2 * commission)\n",
    "    short_bench = pl.Series(short - bench - 2 * commission)\n",
    "\n",
    "    long_cum = long_fee.cum_sum()\n",
    "    short_cum = short_fee.cum_sum()\n",
    "    bench_cum = bench_fee.cum_sum()\n",
    "\n",
    "    long_short_cum = long_short.cum_sum()\n",
    "    long_bench_cum = long_bench.cum_sum()\n",
    "    bench_short_cum = bench_short.cum_sum()\n",
    "    bench_long_cum = bench_long.cum_sum()\n",
    "    short_long_cum = short_long.cum_sum()\n",
    "    short_bench_cum = short_bench.cum_sum()\n",
    "\n",
    "    long_short_stat_result: FactorStatResult = factor_stats(365, long_short)\n",
    "    short_long_stat_result: FactorStatResult = factor_stats(365, short_long)\n",
    "    if long_short_stat_result.sharpe > short_long_stat_result.sharpe:\n",
    "        ret_stat_result = long_short_stat_result\n",
    "    else:\n",
    "        ret_stat_result = short_long_stat_result\n",
    "\n",
    "\n",
    "    return ic_stat, rank_ic_stat, ret_stat_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_column num: 2160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing factors:  19%|█▉        | 417/2160 [04:20<25:46,  1.13it/s]"
     ]
    }
   ],
   "source": [
    "all_column = [col for col in roll_df.columns if \"rolling\" in col]\n",
    "print (f'all_column num: {len (all_column)}')\n",
    "\n",
    "# Initialize lists to store results\n",
    "results = []\n",
    "factor_names = []\n",
    "\n",
    "column_names = []\n",
    "have_column_name = False\n",
    "# all_column = ['rolling_open_skew_40']\n",
    "# all_column = all_column[:10]\n",
    "# Collect results for each factor\n",
    "for each_factor in tqdm (all_column, desc=\"Analyzing factors\"):\n",
    "    ic_stat_dict, rank_ic_stat_dict, ret_stat_result  = analyse_single_factor(roll_df, each_factor)\n",
    "    # print(f\"ic_stat_dict: {ic_stat_dict}\")\n",
    "    # print(f\"rank_ic_stat_dict: {rank_ic_stat_dict}\")\n",
    "    factor_results = []\n",
    "\n",
    "    for key, value in ic_stat_dict.items():\n",
    "        if \"Count\" in key or \"T-Value\" in key:\n",
    "            continue\n",
    "        factor_results.append(value)\n",
    "        if not have_column_name:\n",
    "            column_names.append(\"IC\\n\" + key)\n",
    "\n",
    "    for key, value in rank_ic_stat_dict.items():\n",
    "        if \"Count\" in key or \"T-Value\" in key:\n",
    "            continue\n",
    "        factor_results.append(value)\n",
    "        if not have_column_name:\n",
    "            column_names.append(\"Rank IC\\n\" + key)\n",
    "    factor_results.append(ret_stat_result.sharpe)\n",
    "    factor_results.append(ret_stat_result.calmar_ratio)\n",
    "\n",
    "    have_column_name = True\n",
    "\n",
    "    results.append(factor_results)\n",
    "    factor_names.append(each_factor)\n",
    "\n",
    "# print (f'result df shape: {results.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results\n",
    "tmp_results = []\n",
    "std_len = len (results[0])\n",
    "single_zero_list = [[0] * std_len][0]\n",
    "print (single_zero_list)\n",
    "\n",
    "for i in results:\n",
    "    if len (i) == std_len:\n",
    "        tmp_results.append (i)\n",
    "    else:\n",
    "        tmp_results.append (single_zero_list)\n",
    "print (len (results), len (tmp_results))\n",
    "# results = tmp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to a 2D numpy array\n",
    "results_array = np.array(tmp_results)\n",
    "# print(\"results_array shape:\", results_array.shape, results_array)\n",
    "\n",
    "results_df = pd.DataFrame(results_array, index=factor_names, columns=column_names + ['sharpe', 'calmar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_scale(data):\n",
    "    def scale_column(col):\n",
    "        if col.dtype != 'object':\n",
    "            vmin, vmax = col.min(), col.max()\n",
    "            if vmin == vmax:\n",
    "                return ['background-color: white'] * len(col)\n",
    "            return [\n",
    "                f'background-color: rgba(255, 0, 0, {0.6 * (x-vmin)/(vmax-vmin)})' if x > 0 else\n",
    "                f'background-color: rgba(0, 0, 255, {0.6 * (vmax-x)/(vmax-vmin)})' if x < 0 else\n",
    "                'background-color: white'\n",
    "                for x in col\n",
    "            ]\n",
    "        return [''] * len(col)\n",
    "\n",
    "    return pd.DataFrame(data.apply(scale_column), index=data.index, columns=data.columns)\n",
    "\n",
    "# Apply the color scaling to the original results DataFrame\n",
    "styled_df = results_df.style.apply(color_scale, axis=None)\n",
    "\n",
    "# Set precision for floating point numbers\n",
    "styled_df = styled_df.format(\"{:.4f}\")\n",
    "\n",
    "# Display the styled DataFrame\n",
    "# display(styled_df)\n",
    "\n",
    "# Optional: If you want to save this as an HTML file for later viewing\n",
    "styled_df.to_html('factor_analysis_results.html')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter for sharpe > 1 and sort by sharpe in descending order\n",
    "filtered_and_sorted_df = results_df[results_df['sharpe'] > 1].sort_values(by='sharpe', ascending=False)\n",
    "\n",
    "# Display the filtered and sorted DataFrame\n",
    "display(filtered_and_sorted_df)\n",
    "# print(\"List of all factor names:\")\n",
    "# for factor_name in filtered_and_sorted_df.index:\n",
    "#     print(factor_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_utils import calculate_and_plot_factor_correlations\n",
    "# BASIC_FACTOR_COLUMNS = ['open', 'high', 'low', 'close', 'volume', 'quote_volume']\n",
    "\n",
    "# Convert filtered_and_sorted_df to a Polars DataFrame\n",
    "filtered_and_sorted_pl = pl.from_pandas(filtered_and_sorted_df.reset_index())\n",
    "\n",
    "# Get the list of factor names (which are now in the 'index' column)\n",
    "factor_columns = filtered_and_sorted_pl['index'].to_list()\n",
    "\n",
    "filted_factor_df = roll_df.select(roll_df.columns[:6] + factor_columns)\n",
    "\n",
    "# 为了方便计算corr，把nan填充为0\n",
    "filted_factor_df = filted_factor_df.with_columns(\n",
    "    [pl.col(col).fill_null(0).fill_nan(0) for col in factor_columns]\n",
    ")\n",
    "\n",
    "# check the correlation of factor\n",
    "# corr_df = calculate_and_plot_factor_correlations(filted_factor_df)\n",
    "# print(\"Top factor correlations:\")\n",
    "# print(corr_df.head(20))\n",
    "filted_factor_df[factor_columns].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_utils import select_low_correlation_factors\n",
    "print (f'factor_columns: {factor_columns}')\n",
    "select_low_correlation_factors(filted_factor_df, factor_columns, correlation_threshold=0.5, method='greedy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "talib_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
